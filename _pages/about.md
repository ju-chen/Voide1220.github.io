---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>

Hello! I’m Chen Ju (鞠陈).

I'm a PhD candidate at <a href="https://mediabrain.sjtu.edu.cn/">MediaBrain Group</a>, Shanghai Jiao Tong University, advised by <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Prof. Ya Zhang</a>, <a href="https://weidixie.github.io/">Prof. Weidi Xie</a> and <a href="https://siheng-chen.github.io/">Prof. Siheng Chen</a>.  

Currently, I collaborate closely with some outstanding researchers from PanGu Large Model Team (盘古大模型), Huawei Cloud BU:   &emsp; &emsp; &emsp; &emsp; <a href="https://scholar.google.com/citations?user=61b6eYkAAAAJ">Prof. Qi Tian</a>, <a href="https://scholar.google.com/citations?user=EEMm7hwAAAAJ&hl=zh-CN&oi=ao">Dr. Lingxi Xie</a>, <a href="https://scholar.google.com.hk/citations?user=Ud6aBAcAAAAJ&hl=zh-CN&oi=ao">Dr. Xiaopeng Zhang</a>, <a href="https://scholar.google.com.hk/citations?user=RDwnNsQAAAAJ&hl=zh-CN&oi=ao">Dr. Jianlong Chang</a>, and <a href="https://scholar.google.com.hk/citations?user=hCr8Km8AAAAJ&hl=zh-CN&oi=ao">Dr. Peisen Zhao</a>.

I also collaborate closely with some outstanding researchers from Alibaba Group: <a href="https://scholar.google.com.hk/citations?user=78vU1IUAAAAJ&hl=zh-CN&oi=ao">Dr. Weilin Huang</a>, <a href="https://scholar.google.com.hk/citations?user=qBTDCawAAAAJ&hl=zh-CN&oi=ao">Dr. Shuai Xiao</a>, and <a href="https://scholar.google.com.hk/citations?user=6Qa2JCwAAAAJ&hl=zh-CN">Dr. Xu Chen</a>.


As a young researcher, your interest and kind citation will definitely mean a lot for me and my collaborators.

<p> <b>Email:</b> ju_chen[at]sjtu[dot]edu[dot]cn / cju[dot]void[at]gmail[dot]com         &emsp; &emsp; &emsp; &emsp; &emsp; &emsp;             
<b> Google Scholar:</b> Citations 330+, H-index 6 </p>  



# 🔥 News
- [*2023.07*] ![new paper](/images/new.gif) Our new work, [aligning LLMs' remarkable semantics for multi-modal understanding system](https://arxiv.org/pdf/2307.02003.pdf) is out!
- [*2023.05*] ![new paper](/images/new.gif) Our new work, [distilling fine-grained priors from stable diffusion for unsupervised object discovery](https://arxiv.org/pdf/2303.09813.pdf) is out!
- [*2023.04*] ![new paper](/images/new.gif) Our new work, [multi-modal GPT prompting for vision-language foundation models](https://arxiv.org/pdf/2303.11732.pdf) is out!
- [*2023.03*] ![new paper](/images/new.gif) Our new work, [collaborative distillation so that multiple foundation pre-trainings complement each other](https://arxiv.org/pdf/2212.09335.pdf) is out!
- [*2023.02*] Our work, [partial supervision with quadruple contrasts for cost-effective vision-language pre-training](https://arxiv.org/pdf/2302.09850.pdf) is out!
- [*2023*] One paper is accepted to ICCV 2023, about finer visual understanding from multiple diffusion models.
- [*2023*] One paper is accepted to CVPR 2023, about effective collaboration of multiple foundation models.
- [*2022*] One paper is accepted to ECCV 2022, about efficient adaptation for vision-language foundation models.  
- [*2022*] One paper is accepted to ACM Multimedia 2022, about cost-effective pre-training for video-audio foundation models.     


# 💻 Researches
My primary research interests lie in 

- Vision-Language-Audio Learning, Multi-Modal Pre-training, Efficient Adaptation, Accelerate Deployment for Downstream Tasks.

- AIGC：Generation or Editing for Image & Video & Music, Conversation-Driven Multi-Modal Understanding and Composition.

- Video Understanding: Retrieval & Caption & Summary for Video Clips, Detection & Classification for Untrimmed Long Videos.

Please feel free to drop me an email for any suggestions or potential collaborations.



# 📝 Publications 
### 📒 Topic: Efficiently Adapt Multi-modal Foundation Models to Unify/Generalize Downstream Tasks
1. [Prompting Visual-Language Models for Efficient Video Understanding](https://arxiv.org/pdf/2112.04478.pdf)  \|  [[Project](https://ju-chen.github.io/efficient-prompt/)]  \| [[Code & Data](https://github.com/ju-chen/Efficient-Prompt)]  \| [[Report](https://mp.weixin.qq.com/s/F8RGa0IQyljfue3fAxvATw)]  \| [[Bibtex](./CITE/cite_prompt.txt)]                                 
**Chen Ju**, Tengda Han, Kunhao Zheng, Ya Zhang and Weidi Xie  
**ECCV 2022**  

1. [Collaborating Vision-Language Pre-training with Weakly-Supervised Video Understanding](https://arxiv.org/pdf/2212.09335.pdf)  \|  [[Project & Code](https://voide1220.github.io/distillation_collaboration/)]  \| [[Bibtex](./CITE/cite_distilling.txt)]                                 
**Chen Ju**, Kunhao Zheng, Jinxiang Liu, Peisen Zhao, Ya Zhang, Jianlong Chang, Qi Tian and Yanfeng Wang      
**CVPR 2023** 

1. [Multi-modal GPT Prompts for Open-Vocabulary Video Understanding](https://arxiv.org/pdf/2303.11732.pdf)   \|   [[Project & Code](https://voide1220.github.io/GPT_prompt/)]  \| [[Bibtex](./CITE/cite_map.txt)]                                                        
**Chen Ju**, Zeqian Li, Peisen Zhao, Ya Zhang, Xiaopeng Zhang, Qi Tian, Yanfeng Wang and Weidi Xie     
**Springer IJCV**


### 📒 Topic: Vision-Language-Audio Foundation Pre-trainings with Strong Generalization but Low Costs
1. [Transformation Invariance and Equivariance for Self-supervised Sound Localization](https://arxiv.org/pdf/2206.12772.pdf)  \| [[Project & Demo](https://jinxiang-liu.github.io/SSL-TIE/)] \| [[Code](https://github.com/jinxiang-liu/SSL-TIE)] \| [[Bibtex](./CITE/cite_audio.txt)]                              
Jinxiang Liu, **Chen Ju**, Weidi Xie and Ya Zhang         
**ACM Multimedia 2022**   

1. [Contrast and Unity for Partially-Supervised Temporal Sentence Grounding](https://arxiv.org/pdf/2302.09850.pdf)  \|   [[Project & Code](https://voide1220.github.io/constraint_union/)]  \|    [[Bibtex](./CITE/cite_partial.txt)]            
**Chen Ju**, Haicheng Wang, Jinxiang Liu, Chaofan Ma, Ya Zhang, Peisen Zhao, Jianlong Chang and Qi Tian          
arXiv preprint 2023

1. [SAM Guided Annotation-free Audio-Visual Cross-modal Segmentation](https://arxiv.org/pdf/2305.11019.pdf)   \|    [[Project & Code](https://jinxiang-liu.github.io/anno-free-AVS/)]  \|     [[Bibtex](./CITE/cite_aavs.txt)]            
Jinxiang Liu, **Chen Ju**, Yu Wang, Ya Zhang, Weidi Xie       
arXiv preprint 2023


### 📒 Topic: Freeze Pre-trainings, Downstream Video Understanding with Limited Annotation & Supervision
1. [Divide and Conquer for Single-frame Temporal Action Localization](https://openaccess.thecvf.com/content/ICCV2021/papers/Ju_Divide_and_Conquer_for_Single-Frame_Temporal_Action_Localization_ICCV_2021_paper.pdf)  \|  [[Project & Demo](https://voide1220.github.io/divide_conquer/)]   \|  [[Bibtex](./CITE/cite_divide.txt)]             
**Chen Ju**, Peisen Zhao, Siheng Chen, Ya Zhang, Yanfeng Wang and Qi Tian                
**ICCV 2021** 

1. [Bottom-Up Temporal Action Localization with
Mutual Regularization](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123530528.pdf) \| [[Demo](https://voide1220.github.io/adapter/)]  \|   [[Code](https://github.com/PeisenZhao/Bottom-Up-TAL-with-MR)]   \|  [[Bibtex](./CITE/cite_bottom.txt)]               
Peisen Zhao, Lingxi Xie, **Chen Ju**, Ya Zhang, Yanfeng Wang and Qi Tian               
**ECCV 2020** 

1. [Adaptive Mutual Supervision for
Weakly-Supervised Temporal Action Localization](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9920676)  \|  [[Project & Demo](https://voide1220.github.io/adapter/)]  \|   [[Bibtex](./CITE/cite_adaptive.txt)]            
**Chen Ju**, Peisen Zhao, Siheng Chen, Ya Zhang, Xiaoyun Zhang and Qi Tian               
**IEEE Transactions on Multimedia** 

1. [Audio-Aware Query-Enhanced Transformer for Audio-Visual Segmentation](https://arxiv.org/abs/2307.13236.pdf)   \|    [[Project & Code](https://jinxiang-liu.github.io/anno-free-AVS/)]  \|  [[Bibtex](./CITE/cite_aqt.txt)]              
Jinxiang Liu, **Chen Ju**, Chaofan Ma, Yanfeng Wang, Yu Wang, Ya Zhang    
**WACV 2023**


### 📒 Topic: AIGC for Video Editing, Music Composition, and Conversation-Driven Visual Understanding
1. [Adapting Diffusion Models Towards Unsupervised Object Discovery](https://arxiv.org/pdf/2303.09813.pdf) \| [[Bibtex](./CITE/cite_diffusion.txt)]               
Chaofan Ma, Yuhuan Yang, **Chen Ju**, Fei Zhang, Jinxiang Liu, Yu Wang, Ya Zhang and Yanfeng Wang                  
arXiv preprint 2023

1. [Multi-Modal Prototypes for Open-Set Semantic Segmentation](https://arxiv.org/pdf/2307.02003.pdf) \| [[Bibtex](./CITE/cite_prototype.txt)]                  
Yuhuan Yang, Chaofan Ma, **Chen Ju**, Ya Zhang and Yanfeng Wang             
arXiv preprint 2023 



### 📒 Topic: Training & Inference Turbo Acceleration for Vision-Language-Audio Understanding & Generation
1. ToDo




# 🗞️ Academic Services
- PC Member & Reviewer: AAAI 2024, ICCV 2023, CVPR 2023, ACM MM 2023, AAAI 2023, ECCV 2022, IEEE T-MM



# 📄 Patents
- CN202010403823.4 [《一种基于自适应采样的弱监督时序动作检测方法及系统》](https://cprs.patentstar.com.cn/Search/Detail?ANE=9AIB2ACA7BEA6GAA8HAA8EEA9BFB9HGE9FCB9AED9BGA9AGA)         
Ya Zhang, **<u>Chen Ju</u>**, Yanfeng Wang. 
- CN202111190861.7 [《一种单帧监督视频时序动作检测与分类方法及系统》](https://cprs.patentstar.com.cn/Search/Detail?ANE=9IBC9FIE9HFF6BEA6DCA4BCA3ACAACGA9GFCDHFA9DFF6CDA)         
Ya Zhang, **<u>Chen Ju</u>**, Peisen Zhao, Siheng Chen, Xiaoyun Zhang, Yanfeng Wang. 
- CN202211056034.3 [《弱监督视频时序动作检测与分类方法及系统》](https://cprs.patentstar.com.cn/Search/Detail?ANE=5CBA3BCAAHIA9GIH9FDA8CFA7FCA9HBEAGFA9CIB9EHFAHGA)       
Ya Zhang, **<u>Chen Ju</u>**, Kunhao Zheng, Jinxiang Liu, Weidi Xie, Yanfeng Wang.  
- CN202211581256.7 [《局部监督长视频时序文本检索方法及系统》](https://cprs.patentstar.com.cn/Search/Detail?ANE=9GHG6CEA9FCA9DEA9IEE9GGE9BGDAIBA9IBB9IBC9EAA9ICH)       
Ya Zhang, **<u>Chen Ju</u>**, Haicheng Wang, Jinxiang Liu, Chaofan Ma, Yanfeng Wang.  
- CN202310913202.4 [《基于属性分解-聚合的开放词汇语义分割方法及系统》](https://cprs.patentstar.com.cn/Search/Detail?ANE=9GHG6CEA9FCA9DEA9IEE9GGE9BGDAIBA9IBB9IBC9EAA9ICH)       
Yanfeng Wang, Chaofan Ma, Yuhuan Yang, **<u>Chen Ju</u>**, Fei Zhang, Ya Zhang.  



# 📖 Educations
- *2018.09 - Now*, PhD candidate, Shanghai Jiao Tong University, Shanghai, China
- *2014.09 - 2018.06*, Undergraduate, University of Electronic Science and Technology of China, Chengdu, China



# 🎖 Honors and Awards
- [*2020 & 2022*] CMIC Outstanding Scholarship at SJTU
- [*2018*] Outstanding Graduates of Sichuan Province
- [*2016 & 2017*] Undergraduate National Scholarship at UESTC



