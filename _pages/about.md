---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>

Hello! Iâ€™m Chen Ju (é é™ˆ).

I'm a PhD candidate at <a href="https://mediabrain.sjtu.edu.cn/">MediaBrain Group</a>, Cooperative Medianet Innovation Center, Shanghai Jiao Tong University, supervised by <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Prof. Ya Zhang</a>, also advised by <a href="https://weidixie.github.io/">Prof. Weidi Xie</a> and <a href="https://siheng-chen.github.io/">Prof. Siheng Chen</a>.  

Currently, I collaborate with researchers from Huawei Cloud: <a href="https://scholar.google.com/citations?user=61b6eYkAAAAJ">Prof. Qi Tian</a>, <a href="https://scholar.google.com.hk/citations?user=Ud6aBAcAAAAJ&hl=zh-CN&oi=ao">Dr. Xiaopeng Zhang</a>, <a href="https://scholar.google.com.hk/citations?user=RDwnNsQAAAAJ&hl=zh-CN&oi=ao">Dr. Jianlong Chang</a>, and <a href="https://scholar.google.com.hk/citations?user=hCr8Km8AAAAJ&hl=zh-CN&oi=ao">Dr. Peisen Zhao</a> closely.

As a young researcher, your interest and kind citation will definitely mean a lot for me and my collaborators.

**Email:** ju_chen[at]sjtu[dot]edu[dot]cn / cju[dot]void[at]gmail[dot]com    
 


# ğŸ”¥ News
<!-- - [*2023*] ![new paper](/images/new.gif) One paper is accepted to DASFAA 2023, about table-and-text question answering. -->
- [*2023*] ![new paper](/images/new.gif) Our new preprint, [Multi-modal Prompt Learning](https://arxiv.org/pdf/2212.09335.pdf) for vision-language foundation models is out!
- [*2023*] ![new paper](/images/new.gif) Our new preprint, [Collaborative Distillation](https://arxiv.org/pdf/2212.09335.pdf) so that multiple pre-trainings complement each other is out!
- [*2022*] One paper is accepted to ECCV 2022, about efficient adaptation for VLP.



# ğŸ’» Researches

My primary research interests lie in Vision-Language-Audio Multi-modal Learning, Video Understanding/Generation, and Music Composition.

Please feel free to drop me an email for any suggestions or potential collaborations.


# ğŸ“ Publications 
### ğŸ“’ Topic: Efficiently Adapt Multi-modal Foundation Models to Unify/Generalize Downstream Tasks
1. [Prompting Visual-Language Models for Efficient Video Understanding](https://arxiv.org/pdf/2112.04478.pdf) \| [[Code & Data](https://github.com/ju-chen/Efficient-Prompt)]  \|  [[Project](https://ju-chen.github.io/efficient-prompt/)]  \| [[Report](https://mp.weixin.qq.com/s/F8RGa0IQyljfue3fAxvATw)]        
**Chen Ju**, Tengda Han, Kunhao Zheng, Ya Zhang and Weidi Xie  
In Proc. of **ECCV 2022**  

1. [Distilling Vision-Language Pre-training to Collaborate with Weakly-Supervised Temporal Action Localization](https://arxiv.org/pdf/2212.09335.pdf)  \|  [[Project](https://ju-chen.github.io/efficient-prompt/)]     
**Chen Ju**, Kunhao Zheng, Jinxiang Liu, Peisen Zhao, Ya Zhang, Jianlong Chang, Yanfeng Wang and Qi Tian    
In Proc. of **arXiv preprint 2023** 

1. [Multi-modal Prompt Learning to Bridge Optical Flow for
Low-Shot Video Understanding](https://arxiv.org/pdf/2212.09335.pdf)   \|  [[Project](https://ju-chen.github.io/efficient-prompt/)]    
**Chen Ju**, Zeqian Li, Peisen Zhao, Ya Zhang, Qi Tian and Weidi Xie     
**arXiv preprint 2023** 


### ğŸ“’ Topic: Vision-Language-Audio Pre-trainings with Strong Generalization but Low Costs
1. [Exploiting Transformation Invariance and Equivariance for Self-supervised Sound Localisation](https://arxiv.org/pdf/2206.12772.pdf)  \|  [[Code](https://github.com/jinxiang-liu/SSL-TIE)] \| [[Project](https://jinxiang-liu.github.io/SSL-TIE/)] \|  [[Demo](https://www.bilibili.com/video/BV1Dt4y1t7PM/?zw)]       
Jinxiang Liu, **Chen Ju**, Weidi Xie and Ya Zhang         
In Proc. of **ACM Multimedia 2022**   

1. [Quadruple Constraint Learning for Partially-Supervised Temporal Sentence Grounding](https://arxiv.org/pdf/2212.09335.pdf)  \| [[Bibtex](https://ju-chen.github.io/efficient-prompt/)]    
**Chen Ju**, Haicheng Wang, Jinxiang Liu, Chaofan Ma, Ya Zhang, Peisen Zhao, Jianlong Chang and Qi Tian          
**arXiv preprint 2023** 


### ğŸ“’ Topic: Freeze Pre-trainings, Downstream Video Understanding with Limited Annotation & Supervision
1. [Divide and Conquer for Single-frame Temporal Action Localization](https://openaccess.thecvf.com/content/ICCV2021/papers/Ju_Divide_and_Conquer_for_Single-Frame_Temporal_Action_Localization_ICCV_2021_paper.pdf)   \|  [[Bibtex](https://ju-chen.github.io/efficient-prompt/)]    
**Chen Ju**, Peisen Zhao, Siheng Chen, Ya Zhang, Yanfeng Wang and Qi Tian                
In Proc. of **ICCV 2021** 

1. [Bottom-Up Temporal Action Localization with
Mutual Regularization](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123530528.pdf) \| [[Code](https://github.com/PeisenZhao/Bottom-Up-TAL-with-MR)]    
Peisen Zhao, Lingxi Xie, **Chen Ju**, Ya Zhang, Yanfeng Wang and Qi Tian               
In Proc. of **ECCV 2020** 

1. [Adaptive Mutual Supervision for
Weakly-Supervised Temporal Action Localization](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9920676)   \|  [[Bibtex](https://ju-chen.github.io/efficient-prompt/)]    
**Chen Ju**, Peisen Zhao, Siheng Chen, Ya Zhang, Xiaoyun Zhang and Qi Tian               
**IEEE Transactions on Multimedia** 


### ğŸ“’ Topic: AIGC (Stable Diffusion for Video Generation and Music Composition)
1. Adapting Diffusion Models Towards Unsupervised Salient Object Detection         
Chaofan Ma, Yuhuan Yang, **Chen Ju**, Jinxiang Liu, Yanfeng Wang, Ya Zhang and Yu Wang       
In Proc. of **arXiv preprint 2023**   



# ğŸ—ï¸ Academic Services
- PC Member & Reviewer: ICCV 2023, CVPR 2023, AAAI 2023, ECCV 2022



# ğŸ“„ Patents
- CN202211581256.7 [ã€Šå±€éƒ¨ç›‘ç£é•¿è§†é¢‘æ—¶åºæ–‡æœ¬æ£€ç´¢æ–¹æ³•åŠç³»ç»Ÿã€‹](https://cprs.patentstar.com.cn/Search/Detail?ANE=9HEE9IFE9GDC9FDB5AEA9IDC9HHF9CIG7FCA9AFF9EDE9IBD)       
Ya Zhang, **<u>Chen Ju</u>**, Haicheng Wang, Jinxiang Liu, Chaofan Ma, Yanfeng Wang.       
- CN202211056034.3 [ã€Šå¼±ç›‘ç£è§†é¢‘æ—¶åºåŠ¨ä½œæ£€æµ‹ä¸åˆ†ç±»æ–¹æ³•åŠç³»ç»Ÿã€‹](https://cprs.patentstar.com.cn/Search/Detail?ANE=9HEE9IFE9GDC9FDB5AEA9IDC9HHF9CIG7FCA9AFF9EDE9IBD)       
Ya Zhang, **<u>Chen Ju</u>**, Kunhao Zheng, Jinxiang Liu, Weidi Xie, Yanfeng Wang.      
- CN202111190861.7 [ã€Šä¸€ç§å•å¸§ç›‘ç£è§†é¢‘æ—¶åºåŠ¨ä½œæ£€æµ‹ä¸åˆ†ç±»çš„æ–¹æ³•åŠç³»ç»Ÿã€‹](https://cprs.patentstar.com.cn/Search/Detail?ANE=9HEE9IFE9GDC9FDB5AEA9IDC9HHF9CIG7FCA9AFF9EDE9IBD)         
Ya Zhang, **<u>Chen Ju</u>**, Peisen Zhao, Siheng Chen, Xiaoyun Zhang, Yanfeng Wang.       
- CN202010403823.4 [ã€Šä¸€ç§å¼±ç›‘ç£è§†é¢‘æ—¶åºåŠ¨ä½œæ£€æµ‹ä¸ç±»åˆ«é¢„æµ‹çš„æ–¹æ³•åŠç³»ç»Ÿã€‹](https://cprs.patentstar.com.cn/Search/Detail?ANE=9HEE9IFE9GDC9FDB5AEA9IDC9HHF9CIG7FCA9AFF9EDE9IBD)    
Ya Zhang, **<u>Chen Ju</u>**, Yanfeng Wang. 



# ğŸ“– Educations
- *2018.09 - Now*, PhD, Shanghai Jiao Tong University, Shanghai, China
- *2014.09 - 2018.06*, Undergraduate, University Of Electronic Science And Technology Of China, Chengdu, China



# ğŸ– Honors and Awards
- [*2020 & 2022*] CMIC Outstanding Scholarship at SJTU
- [*2018*] Outstanding Graduates of Sichuan Province
- [*2016 & 2017*] Undergraduate National Scholarship at UESTC



