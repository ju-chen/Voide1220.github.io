

<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!--
  <script src="./resources/jsapi" type="text/javascript"></script>
  <script type="text/javascript" async>google.load("jquery", "1.3.2");</script>
 -->

<style type="text/css">
  @font-face {
   font-family: 'Avenir Book';
   src: url("./fonts/Avenir_Book.ttf"); /* File to be stored at your site */
   }

  body {
    font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:14px;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
  }
  h1 {
    font-weight:300;
  }
  h2 {
    font-weight:300;
  }

  p {
    font-weight:300;
    line-height: 1.4;
  }

  code {
    font-size: 0.8rem;
    margin: 0 0.2rem;
    padding: 0.5rem 0.8rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
  }

  pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
  }

  pre.prettyprint > code {
    border: none;
  }


  .container {
        display: flex;
        align-items: center;
        justify-content: center
  }
  .image {
        flex-basis: 40%
  }
  .text {
        padding-left: 20px;
        padding-right: 20px;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;

  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>

	<title>Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Large Models</title>
</head>

<body>
	<br>
	<center>
	<span style="font-size:36px">Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Large Models</span><br><br><br>
	</center>
	
	<table align="center" width="800px">
            <tbody><tr>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://voide1220.github.io/">Chen Ju</a><sup>1</sup></span>
                </center>
			    
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://scholar.google.com.hk/citations?user=x0Uk7S8AAAAJ&hl=zh-CN&oi=ao">Haicheng Wang</a><sup>1,2</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://mediabrain.sjtu.edu.cn/members/">Haozhe Cheng</a><sup>2</sup></span>
                </center>    	    
                </tr>
        </tbody></table><br>

	<table align="center" width="800px">
            <tbody><tr>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://scholar.google.com.hk/citations?user=6Qa2JCwAAAAJ&hl=zh-CN">Xu Chen</a><sup>1</sup></span>
                </center>
			    
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://scholar.google.com.hk/citations?user=o4SDCAYAAAAJ&hl=zh-CN&oi=ao">Zhonghua Zhai</a><sup>1</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://whuang.org/">Weilin Huang</a><sup>1</sup></span>
                </center>    	    
                </tr>
        </tbody></table><br>
	
		
	<table align="center" width="800px">
            <tbody><tr>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="">Jinsong Lan</a><sup>1</sup></span>
                </center>
			    
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://sites.google.com/view/xiao-shuai/home">Shuai Xiao</a><sup>1</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://scholar.google.com.hk/citations?user=3gHhO9QAAAAJ&hl=zh-CN&oi=ao">Bo Zheng</a><sup>1</sup></span>
                </center>    	    
                </tr>
        </tbody></table><br>

	
	  <table align="center" width="700px">
         <tbody><tr>
                    <td align="center" width="50px">
              <center>
                    <span style="font-size:16px"></span>
                </center>
                </td>
                    <td align="center" width="300px">
              <center>
                    <span style="font-size:16px"><sup>1</sup>TAO Technology, Alibaba Group</span>
                </center>

			    
                </td>
                    <td align="center" width="300px">
              <center>
                    <span style="font-size:16px"><sup>2</sup>Shanghai Jiao Tong University</span>
                </center>
                </td>
        </tr></tbody>
	</table>
	
			<br>
			<table align=center width=500px>
				<tr>
					<td align=center width=500px>
						<center>
							<span style="font-size:22px">
								<span style="font-size:20px">ECCV 2024</span>
							</span>
						</center>
					</td>
				</tr>
			</table>	
	

      <br><hr>
	<table align="center" width="700px">
            <tbody><tr>
              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    <a href=""> Code </a>
                  </span>
                </center>
              </td>

              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    <a href="https://arxiv.org/abs/2312.07408"> Paper </a>
                  </span>
                </center>
              </td>

              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    <a href="./cite_turbo.txt"> Bibtex </a>
                  </span>
                </center>
              </td>
            </tr></tbody>
      </table>


      <br><hr>
	<center><h1>Problem</h1></center>
      <br>
        <center>
          <div class="container">
	    <div class="row">
	      <center>
	        <img src="./image/intro.png" alt="alt text" style="width: 80%; object-fit: cover; max-width:80%;"></a>
	      </center>
		  
	      </div>
        </center>
      </center>
	<p> Left: the trouble with applying VLMs is the high-cost issue. Right: to accelerate VLMs, most existing ideas focus on the model perspective (pruning & quantization). While our Turbo explores de-redundancy from the data perspective. </p>

      <br><hr>
        <table align=center width=850px>
	<center><h1>Abstract</h1></center>
	<tr>
		<td>
            Vision-Language Large Models (VLMs) recently become primary backbone of AI, due to the impressive performance. However, their expensive computation costs, i.e., throughput and delay, impede potentials in the real-world scenarios. To achieve acceleration for VLMs, most existing methods focus on the model perspective: pruning, distillation, quantization, but completely overlook the data-perspective redundancy. To fill the overlook, this paper pioneers the severity of data redundancy, and designs one plug-and-play Turbo module guided by information degree to prune inefficient tokens from visual or textual data. In pursuit of efficiency-performance trade-offs, information degree takes two crucial factors into consideration: mutual redundancy and semantic value. Concretely, the former evaluates data duplication between sequential tokens; while the latter evaluates each token by its contribution to the overall semantics. As a result, tokens with high information degree carry less redundancy and stronger semantics. For VLMs' calculation, Turbo works as a user-friendly plug-in that sorts data referring to information degree, utilizing only top-level ones to save costs. Its advantages are multifaceted, e.g., being generally compatible to various VLMs across understanding and generation, simple use without re-training and trivial engineering efforts. On multiple VLMs benchmarks, we fully experiment to reveal good acceleration of Turbo, under negligible performance drop. 
		</td>
	</tr>
	</table>
     
	
      <br><hr>
	<center><h1>Framework Overview</h1></center>
      <br>
        <center>
          <div class="container">
	    <div class="row">
	      <center>
	        <img src="./image/frame.png" alt="alt text" style="width: 100%; object-fit: cover; max-width:100%;"></a>
	      </center>
	      
	      </div>
        </center>
      </center>
	<p> As one plug-in, Turbo compresses data to cut computing overheads for VLMs, across understanding/generation and uni-/multi-modality. It sorts then merges tokens by information degree (mutual redundancy and semantic value) for understanding tasks; while sorts, merges and restores VLMs’ tokens for generation tasks, owning good universality and practicality.
        <br><hr>

        <center><h1>Empirical Study</h1></center>
        <br>
          <center>
            <div class="container">
          <div class="row">
            <center>
              <img src="./image/diag.png" alt="alt text" style="width: 100%; object-fit: cover; max-width:100%;"></a>
            </center>
            
            </div>
          </center>
        </center>
      <p> Empirical Evaluation of Token Redundancy & Attention Concentration on BLIP fine-tuned for multi-modal retrieval. Results reveal the non-negligible redundancy in the token sequence from perspectives of semantics and similarity.
        <br><hr>

	<center><h1>Experiments</h1></center>
        <p><img class="center"  src="./image/expb.png" width="900px"></p>
        <p><img class="center"  src="./image/expa.png" width="900px"></p>


	<center><h1>Ablation Study</h1></center>
        <p><center><img class="center"  src="./image/ablation.png" width="300px"></center></p>
	<p> Ablation Study on Drop Ratio. Semantic value retains superior performance when ratio is small, mutual redundancy possesses better stability on the large ratio. By combining two components, Turbo gets competitive results and stability on the whole scope.
        <p><img class="center"  src="./image/exp5.png" width="800px"></p>

	<center><h1>Robustness</h1></center>
        <p><img class="center"  src="./image/robust.png" width="800px"></p>
	<p> Ablation Study of Balancing Coefficient. On image captioning using BLIP (VIT-Base and VIT Large), these results prove our robustness, as the performance varies slightly.

	<center><h1>Visualization Results</h1></center>
        <p><center><img class="center"  src="./image/merge.png" width="600px"></center></p>
	<p> Left: Turbo merges background patches, while retains foreground patches with semantics, preserving more key information. Right: The quality
        of text-to-image generation is close before and after Turbo acceleration.
        
    <center><h1>Comparison with Previous SOTA</h1></center>
        <p><center><img class="center"  src="./image/res.png" width="600px"></center></p>
    <p> Generation comparisons for ToMe and Turbo. Compared with ToMe, Turbo retains more details and has better quality.  
      <br>
      <hr>
      <center> <h1> Acknowledgements </h1> </center>
	<p>
		This research is completed during research internship, supported by Alibaba Group. 
	</p>
  
      <br>


<br>
</body>
</html>
