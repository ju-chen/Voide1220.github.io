

<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!--
  <script src="./resources/jsapi" type="text/javascript"></script>
  <script type="text/javascript" async>google.load("jquery", "1.3.2");</script>
 -->

<style type="text/css">
  @font-face {
   font-family: 'Avenir Book';
   src: url("./fonts/Avenir_Book.ttf"); /* File to be stored at your site */
   }

  body {
    font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:14px;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
  }
  h1 {
    font-weight:300;
  }
  h2 {
    font-weight:300;
  }

  p {
    font-weight:300;
    line-height: 1.4;
  }

  code {
    font-size: 0.8rem;
    margin: 0 0.2rem;
    padding: 0.5rem 0.8rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
  }

  pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
  }

  pre.prettyprint > code {
    border: none;
  }


  .container {
        display: flex;
        align-items: center;
        justify-content: center
  }
  .image {
        flex-basis: 40%
  }
  .text {
        padding-left: 20px;
        padding-right: 20px;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;

  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>

	<title>Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Large Models</title>
</head>

<body>
	<br>
	<center>
	<span style="font-size:36px">Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Large Models</span><br><br><br>
	</center>
	
	<table align="center" width="800px">
            <tbody><tr>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://voide1220.github.io/">Chen Ju</a><sup>1,2</sup></span>
                </center>
			    
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://scholar.google.com.hk/citations?user=x0Uk7S8AAAAJ&hl=zh-CN&oi=ao">Haicheng Wang</a><sup>1,2</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://mediabrain.sjtu.edu.cn/members/">Haozhe Cheng</a><sup>2</sup></span>
                </center>
			    
                </td>
                    <td align="center" width="160px">
	            <center>
                <span style="font-size:16px"><a href="https://scholar.google.com.hk/citations?user=6Qa2JCwAAAAJ&hl=zh-CN">Xu Chen</a><sup>1</sup></span>
                </center>		    
                </tr>
        </tbody></table><br>
			    
			    
		
	<table align="center" width="800px">	    
                <tr>
                    <td align="center" width="160px">	    
              <center>
                <span style="font-size:16px"><a href="https://scholar.google.com.hk/citations?user=o4SDCAYAAAAJ&hl=zh-CN&oi=ao">Zhonghua Zhai</a><sup>1</sup></span>
                </center> 				
			
		</td>
                    <td align="center" width="160px">	    
              <center>
                <span style="font-size:16px"><a href="https://whuang.org/">Weilin Huang</a><sup>1</sup></span>
                </center> 
			    
		</td>
                    <td align="center" width="160px">	    
              <center>
                <span style="font-size:16px"><a href="">Jinsong Lan</a><sup>1</sup></span>
                </center>      
			    
                </td>
                    <td align="center" width="160px">	    
              <center>
                <span style="font-size:16px"><a href="https://sites.google.com/view/xiao-shuai/home">Shuai Xiao</a><sup>1</sup></span>
                </center>  			    
            </tr>
		
        </tbody></table><br>
	
	
	
	  <table align="center" width="700px">
         <tbody><tr>
                    <td align="center" width="50px">
              <center>
                    <span style="font-size:16px"></span>
                </center>
                </td>
                    <td align="center" width="300px">
              <center>
                    <span style="font-size:16px"><sup>1</sup>Tao Technology, Alibaba Group</span>
                </center>

			    
                </td>
                    <td align="center" width="300px">
              <center>
                    <span style="font-size:16px"><sup>2</sup>CMIC, Shanghai Jiao Tong University</span>
                </center>
                </td>
        </tr></tbody>
	</table>
	
			<br>
			<table align=center width=500px>
				<tr>
					<td align=center width=500px>
						<center>
							<span style="font-size:22px">
								<span style="font-size:20px">ECCV 2024</span>
							</span>
						</center>
					</td>
				</tr>
			</table>	
	

      <br><hr>
	<table align="center" width="700px">
            <tbody><tr>
              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    <a href="https://github.com/ju-chen/Efficient-Prompt"> Code </a>
                  </span>
                </center>
              </td>

              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    <a href="https://arxiv.org/abs/2312.07408"> Paper </a>
                  </span>
                </center>
              </td>

              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    <a href="./cite_turbo.txt"> Bibtex </a>
                  </span>
                </center>
              </td>
            </tr></tbody>
      </table>


      <br><hr>
	<center><h1>Problem</h1></center>
      <br>
        <center>
          <div class="container">
	    <div class="row">
	      <center>
	        <img src="./image/intro.png" alt="alt text" style="width: 80%; object-fit: cover; max-width:80%;"></a>
	      </center>
		  
	      </div>
        </center>
      </center>
	<p> Left: the trouble with applying VLMs is the high-cost issue. Right: to acceler-
        ate VLMs, most existing ideas focus on the model perspective (pruning & quantization).
        While our Turbo explores de-redundancy from the data perspective. </p>

      <br><hr>
        <table align=center width=850px>
	<center><h1>Abstract</h1></center>
	<tr>
		<td>
            Vision-Language Large Models (VLMs) recently become primary backbone of AI, due to the impressive performance. However, their expensive computation costs, i.e., throughput and delay, impede potentials in the real-world scenarios. To achieve acceleration for VLMs, most existing methods focus on the model perspective: pruning, distillation, quantization, but completely overlook the data-perspective redundancy. To fill the overlook, this paper pioneers the severity of data redundancy, and designs one plug-and-play Turbo module guided by information degree to prune inefficient tokens from visual or textual data. In pursuit of efficiency-performance trade-offs, information degree takes two crucial factors into consideration: mutual redundancy and semantic value. Concretely, the former evaluates data duplication between sequential tokens; while the latter evaluates each token by its contribution to the overall semantics. As a result, tokens with high information degree carry less redundancy and stronger semantics. For VLMs' calculation, Turbo works as a user-friendly plug-in that sorts data referring to information degree, utilizing only top-level ones to save costs. Its advantages are multifaceted, e.g., being generally compatible to various VLMs across understanding and generation, simple use without re-training and trivial engineering efforts. On multiple VLMs benchmarks, we fully experiment to reveal good acceleration of Turbo, under negligible performance drop. 
		</td>
	</tr>
	</table>
     
	
      <br><hr>
	<center><h1>Framework Overview</h1></center>
      <br>
        <center>
          <div class="container">
	    <div class="row">
	      <center>
	        <img src="./image/frame.png" alt="alt text" style="width: 100%; object-fit: cover; max-width:100%;"></a>
	      </center>
	      
	      </div>
        </center>
      </center>
	<p> As one plug-in module, Turbo compresses data to cut computing overheads for various VLMs, across understanding/generation and uni-/multi-modality. It sorts then merges tokens by information degree (mutual redundancy $\mathcal{R}$ and semantic value $\mathcal{A}$) for understanding tasks; while sorts, merges and restores VLMs’ tokens for generation tasks, owning good universality and practicality.
        <br><hr>

        <center><h1>Empirical Study</h1></center>
        <br>
          <center>
            <div class="container">
          <div class="row">
            <center>
              <img src="./image/diag.png" alt="alt text" style="width: 100%; object-fit: cover; max-width:100%;"></a>
            </center>
            
            </div>
          </center>
        </center>
      <p> Empirical Evaluation of Token Redundancy & Attention Concentration on BLIP fine-tuned for multi-modal retrieval. Results reveal the non-negligible redundancy in the token sequence from perspectives of semantics and similarity.
        <br><hr>

	<center><h1>Experiments</h1></center>
        <p><img class="center"  src="./image/expb.png" width="900px"></p>
        <p><img class="center"  src="./image/expa.png" width="900px"></p>


	<center><h1>Ablation Study</h1></center>
        <p><center><img class="center"  src="./image/ablation.png" width="600px"></center></p>
	<p> Ablation Study on Drop Ratio Y. Semantic value retains superior performance when Y is small, mutual redundancy possesses better stability on the large Y. By combining these two components, Turbo obtains competitive results and stability on the whole scope.
        <p><img class="center"  src="./image/exp5.png" width="800px"></p>

	<center><h1>Robustness</h1></center>
        <p><img class="center"  src="./image/robust.png" width="800px"></p>
	<p> Ablation Study of Balancing Coefficient α. On image captioning using BLIP (VIT-Base and VIT Large), these results prove our robustness, as the performance varies slightly.

	<center><h1>Visualization Results</h1></center>
        <p><center><img class="center"  src="./image/merge.png" width="600px"></center></p>
	<p> Left: Turbo merges background patches, while retains foreground patches with semantics, preserving more key information. Right: The quality
        of text-to-image generation is close before and after Turbo acceleration.
        
    <center><h1>Comparison with Previous SOTA</h1></center>
        <p><center><img class="center"  src="./image/res.png" width="600px"></center></p>
    <p> Quality comparison on generation task for ToMe and Turbo. Compared with ToMe, Turbo retains more details and has better generation quality.  
      <br>
      <hr>
      <center> <h1> Acknowledgements </h1> </center>
	<p>
		This research is supported by Alibaba Group.
	</p>
  
      <br>


<br>
</body>
</html>
